{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNFVMtUhMt7l"
   },
   "source": [
    "# Fashion MNIST using Custom Training Loop\n",
    "[Fashion MNIST](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NenrAcsiM7Zl"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkMXve8XuN5X"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "  \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.ticker as mticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtcG5Of7M-IV"
   },
   "source": [
    "## Load and Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1qm4y2FmvWJ"
   },
   "outputs": [],
   "source": [
    "train_data, info = tfds.load(\"fashion_mnist\", split = \"train\", with_info = True, data_dir='./data/', download=False)\n",
    "test_data = tfds.load(\"fashion_mnist\", split = \"test\", data_dir='./data/', download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbliOEMHNiug"
   },
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser/pants\", \"Pullover shirt\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxwzgw3BmkoD"
   },
   "outputs": [],
   "source": [
    "def format_image(data):        \n",
    "    image = data[\"image\"]\n",
    "    image = tf.reshape(image, [-1])\n",
    "    image = tf.cast(image, 'float32')\n",
    "    image = image / 255.0\n",
    "    return image, data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c26dmIL5nmNU"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.map(format_image)\n",
    "test_data = test_data.map(format_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9qdsNPen5-F"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train = train_data.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "test =  test_data.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuCf0s7eOxKQ"
   },
   "source": [
    "## Define the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HU3qcM9WBcMh"
   },
   "outputs": [],
   "source": [
    "def base_model():\n",
    "  inputs = tf.keras.Input(shape=(784,), name='digits')\n",
    "  x = tf.keras.layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "  x = tf.keras.layers.Dense(64, activation='relu', name='dense_2')(x)\n",
    "  outputs = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(x)\n",
    "  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxaHy1NYPGSb"
   },
   "source": [
    "## Define Optimizer and Loss Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5B3vh6fs84i"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1fJsdYIPTb8"
   },
   "source": [
    "## Define Metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Pa_x-5-CH_V"
   },
   "outputs": [],
   "source": [
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVFI54MpQUDp"
   },
   "source": [
    "## Building Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMPe25Dstn0v"
   },
   "outputs": [],
   "source": [
    "def apply_gradient(optimizer, model, x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    logits = model(x)\n",
    "    loss_value = loss_object(y_true=y, y_pred=logits)\n",
    "  \n",
    "  gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "  \n",
    "  return logits, loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fHoh_hgz2PC"
   },
   "outputs": [],
   "source": [
    "def train_data_for_one_epoch():\n",
    "  losses = []\n",
    "  pbar = tqdm(total=len(list(enumerate(train))), position=0, leave=True, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} ')\n",
    "  for step, (x_batch_train, y_batch_train) in enumerate(train):\n",
    "      logits, loss_value = apply_gradient(optimizer, model, x_batch_train, y_batch_train)\n",
    "      \n",
    "      losses.append(loss_value)\n",
    "      \n",
    "      train_acc_metric(y_batch_train, logits)\n",
    "      pbar.set_description(\"Training loss for step %s: %.4f\" % (int(step), float(loss_value)))\n",
    "      pbar.update()\n",
    "  return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gLJyAJE0YRc"
   },
   "outputs": [],
   "source": [
    "def perform_validation():\n",
    "  losses = []\n",
    "  for x_val, y_val in test:\n",
    "      val_logits = model(x_val)\n",
    "      val_loss = loss_object(y_true=y_val, y_pred=val_logits)\n",
    "      losses.append(val_loss)\n",
    "      val_acc_metric(y_val, val_logits)\n",
    "  return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOO1x3VyuPUV"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = base_model()\n",
    "\n",
    "# Iterate over epochs.\n",
    "epochs = 10\n",
    "epochs_val_losses, epochs_train_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "  print('Start of epoch %d' % (epoch,))\n",
    "  \n",
    "  losses_train = train_data_for_one_epoch()\n",
    "  train_acc = train_acc_metric.result()\n",
    "\n",
    "  losses_val = perform_validation()\n",
    "  val_acc = val_acc_metric.result()\n",
    "\n",
    "  losses_train_mean = np.mean(losses_train)\n",
    "  losses_val_mean = np.mean(losses_val)\n",
    "  epochs_val_losses.append(losses_val_mean)\n",
    "  epochs_train_losses.append(losses_train_mean)\n",
    "\n",
    "  print('\\n Epoch %s: Train loss: %.4f  Validation Loss: %.4f, Train Accuracy: %.4f, Validation Accuracy %.4f' % (epoch, float(losses_train_mean), float(losses_val_mean), float(train_acc), float(val_acc)))\n",
    "  \n",
    "  train_acc_metric.reset_states()\n",
    "  val_acc_metric.reset_states()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltKpkpzKK_Up"
   },
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfGc-gMPLCDn"
   },
   "source": [
    "### Plots for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjzIlGipJwC_"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(train_metric, val_metric, metric_name, title, ylim=5):\n",
    "  plt.title(title)\n",
    "  plt.ylim(0,ylim)\n",
    "  plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "  plt.plot(train_metric,color='blue',label=metric_name)\n",
    "  plt.plot(val_metric,color='green',label='val_' + metric_name)\n",
    "\n",
    "plot_metrics(epochs_train_losses, epochs_val_losses, \"Loss\", \"Loss\", ylim=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3PJnCRIO8bM"
   },
   "outputs": [],
   "source": [
    "# utility to display a row of images with their predictions and true labels\n",
    "def display_images(image, predictions, labels, title, n):\n",
    "\n",
    "  display_strings = [str(i) + \"\\n\\n\" + str(j) for i, j in zip(predictions, labels)] \n",
    "\n",
    "  plt.figure(figsize=(17,3))\n",
    "  plt.title(title)\n",
    "  plt.yticks([])\n",
    "  plt.xticks([28*x+14 for x in range(n)], display_strings)\n",
    "  plt.grid(None)\n",
    "  image = np.reshape(image, [n, 28, 28])\n",
    "  image = np.swapaxes(image, 0, 1)\n",
    "  image = np.reshape(image, [28, 28*n])\n",
    "  plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ybveIIcPgVr"
   },
   "outputs": [],
   "source": [
    "test_inputs = test_data.batch(batch_size=1000001)\n",
    "x_batches, y_pred_batches, y_true_batches = [], [], []\n",
    "\n",
    "for x, y in test_inputs:\n",
    "  y_pred = model(x)\n",
    "  y_pred_batches = y_pred.numpy()\n",
    "  y_true_batches = y.numpy()\n",
    "  x_batches = x.numpy()\n",
    "\n",
    "indexes = np.random.choice(len(y_pred_batches), size=10)\n",
    "images_to_plot = x_batches[indexes]\n",
    "y_pred_to_plot = y_pred_batches[indexes]\n",
    "y_true_to_plot = y_true_batches[indexes]\n",
    "\n",
    "y_pred_labels = [class_names[np.argmax(sel_y_pred)] for sel_y_pred in y_pred_to_plot]\n",
    "y_true_labels = [class_names[sel_y_true] for sel_y_true in y_true_to_plot]\n",
    "display_images(images_to_plot, y_pred_labels, y_true_labels, \"Predicted and True Values\", 10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
