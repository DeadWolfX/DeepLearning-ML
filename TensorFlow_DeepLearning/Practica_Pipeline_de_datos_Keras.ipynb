{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MafkAEDu8Z9Y"
      },
      "source": [
        "## Data pipeline with Keras and tf.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzPRdiuJ8Z9d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Flatten, Dense \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vthGhpsh8Z9f"
      },
      "source": [
        "### Part 1: tf.keras\n",
        "\n",
        "#### The LSUN Dataset\n",
        "\n",
        "In the first part of this assignment, you will use a subset of the [LSUN dataset](https://www.yf.io/p/lsun). This is a large-scale image dataset with 10 scene and 20 object categories. A subset of the LSUN dataset has been provided, and has already been split into training and test sets. The three classes included in the subset are `church_outdoor`, `classroom` and `conference_room`.\n",
        "\n",
        "* F. Yu, A. Seff, Y. Zhang, S. Song, T. Funkhouser and J. Xia. \"LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop\". arXiv:1506.03365, 10 Jun 2015 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc1H3DpB8Z9g"
      },
      "outputs": [],
      "source": [
        "# Save the directory locations for the training, validation and test sets\n",
        "\n",
        "train_dir = 'data/lsun/train'\n",
        "valid_dir = 'data/lsun/valid'\n",
        "test_dir = 'data/lsun/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUYYl46T8Z9h"
      },
      "source": [
        "#### Create a data generator using the ImageDataGenerator class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI1nRIO_8Z9i"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_ImageDataGenerator():\n",
        "    \n",
        "    image_generator = ImageDataGenerator(rescale=(1/255.0))\n",
        "\n",
        "    return image_generator    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DECsbyML8Z9k"
      },
      "outputs": [],
      "source": [
        "# Call the function to get an ImageDataGenerator as specified\n",
        "\n",
        "image_gen = get_ImageDataGenerator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X_MSM248Z9l"
      },
      "source": [
        " [documentation](https://keras.io/preprocessing/image/#imagedatagenerator-class) for the `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y02NTaPg8Z9n"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_generator(image_data_generator, directory, seed=None):\n",
        "    \n",
        "    generator = image_data_generator.flow_from_directory(directory, batch_size=20, classes=['classroom','conference_room','church_outdoor'], \n",
        "                                                         target_size=(64,64), seed=seed, class_mode=\"categorical\")\n",
        "    return generator    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "0afEdrpt8Z9o"
      },
      "outputs": [],
      "source": [
        "#define training and validation generators\n",
        "\n",
        "train_generator = get_generator(image_gen, train_dir)\n",
        "valid_generator = get_generator(image_gen, valid_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pRfKq3h8Z9p"
      },
      "source": [
        "#### Display sample images and labels from the training set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "Hl88hrjl8Z9q"
      },
      "outputs": [],
      "source": [
        "# Display a few images and labels from the training set\n",
        "\n",
        "batch = next(train_generator)\n",
        "batch_images = np.array(batch[0])\n",
        "batch_labels = np.array(batch[1])\n",
        "lsun_classes = ['classroom', 'conference_room', 'church_outdoor']\n",
        "\n",
        "plt.figure(figsize=(16,10))\n",
        "for i in range(20):\n",
        "    ax = plt.subplot(4, 5, i+1)\n",
        "    plt.imshow(batch_images[i])\n",
        "    plt.title(lsun_classes[np.where(batch_labels[i] == 1.)[0][0]])\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0uhUB3E8Z9r"
      },
      "outputs": [],
      "source": [
        "# Reset the training generator\n",
        "\n",
        "train_generator = get_generator(image_gen, train_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V65TsRjI8Z9r"
      },
      "source": [
        "#### Build the neural network model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge7vE1dE8Z9s"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_model(input_shape):\n",
        "    \n",
        "    inputs=Input(shape=input_shape)\n",
        "    x=Conv2D(8,8,activation='relu',padding='same')(inputs)\n",
        "    x=MaxPooling2D(2)(x)\n",
        "    x=Conv2D(4,4,activation='relu',padding='same')(x)\n",
        "    x=MaxPooling2D(2)(x)\n",
        "    x=Flatten()(x)\n",
        "    x=Dense(16,activation='relu')(x)\n",
        "    outputs=Dense(3,activation='softmax')(x)\n",
        "    model=Model(inputs=inputs,outputs=outputs)\n",
        "    \n",
        "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam(0.0005), metrics=['accuracy'])\n",
        "\n",
        "    return model    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVH4iWT38Z9t"
      },
      "outputs": [],
      "source": [
        "# Build and compile the model, print the model summary\n",
        "\n",
        "lsun_model = get_model((64, 64, 3))\n",
        "lsun_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQRI6AsF8Z9t"
      },
      "source": [
        "#### Train the neural network model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "yAwPZQsL8Z9u"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_model(model, train_gen, valid_gen, epochs):\n",
        "    \n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, min_lr=1e-4)\n",
        "    history = model.fit_generator(train_gen, validation_data=valid_gen, epochs=epochs, callbacks=[early_stop,reduce_lr])\n",
        "\n",
        "    return history    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "CvR0rELb8Z9u"
      },
      "outputs": [],
      "source": [
        "# Train the model for (maximum) 50 epochs\n",
        "\n",
        "history = train_model(lsun_model, train_generator, valid_generator, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8-rI9yG8Z9v"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY2PXWzF8Z9v"
      },
      "outputs": [],
      "source": [
        "# plot accuracy vs epoch and loss vs epoch\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(121)\n",
        "try:\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    try:\n",
        "        plt.plot(history.history['acc'])\n",
        "        plt.plot(history.history['val_acc'])\n",
        "    except KeyError:\n",
        "        plt.plot(history.history['categorical_accuracy'])\n",
        "        plt.plot(history.history['val_categorical_accuracy'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZAGls5d8Z9w"
      },
      "source": [
        "#### Create a new data generator with data augmentation\n",
        " [documentation](https://keras.io/preprocessing/image/#imagedatagenerator-class) for the `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8og1TDA08Z9x"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_ImageDataGenerator_augmented():\n",
        "    \n",
        "    datagen = ImageDataGenerator(rescale=1.0/255, \n",
        "                                 rotation_range=30,\n",
        "                                 brightness_range=(0.5, 1.5), \n",
        "                                 horizontal_flip=True)\n",
        "    return datagen    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6hG1hpd8Z9x"
      },
      "outputs": [],
      "source": [
        "# Call the function to get an ImageDataGenerator as specified\n",
        "\n",
        "image_gen_aug = get_ImageDataGenerator_augmented()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVQFDQK58Z9x"
      },
      "outputs": [],
      "source": [
        "# define training and validation generators \n",
        "\n",
        "valid_generator_aug = get_generator(image_gen_aug, valid_dir)\n",
        "train_generator_aug = get_generator(image_gen_aug, train_dir, seed=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvxVF8i88Z9y"
      },
      "outputs": [],
      "source": [
        "# Reset the original train_generator with the same random seed\n",
        "\n",
        "train_generator = get_generator(image_gen, train_dir, seed=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z90-WdIL8Z9y"
      },
      "source": [
        "#### Display sample augmented images and labels from the training set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "5mvsV9_c8Z9z"
      },
      "outputs": [],
      "source": [
        "# Display a few images and labels from the non-augmented and augmented generators\n",
        "\n",
        "batch = next(train_generator)\n",
        "batch_images = np.array(batch[0])\n",
        "batch_labels = np.array(batch[1])\n",
        "\n",
        "aug_batch = next(train_generator_aug)\n",
        "aug_batch_images = np.array(aug_batch[0])\n",
        "aug_batch_labels = np.array(aug_batch[1])\n",
        "\n",
        "plt.figure(figsize=(16,5))\n",
        "plt.suptitle(\"Unaugmented images\", fontsize=16)\n",
        "for n, i in enumerate(np.arange(10)):\n",
        "    ax = plt.subplot(2, 5, n+1)\n",
        "    plt.imshow(batch_images[i])\n",
        "    plt.title(lsun_classes[np.where(batch_labels[i] == 1.)[0][0]])\n",
        "    plt.axis('off')\n",
        "plt.figure(figsize=(16,5))\n",
        "plt.suptitle(\"Augmented images\", fontsize=16)\n",
        "for n, i in enumerate(np.arange(10)):\n",
        "    ax = plt.subplot(2, 5, n+1)\n",
        "    plt.imshow(aug_batch_images[i])\n",
        "    plt.title(lsun_classes[np.where(aug_batch_labels[i] == 1.)[0][0]])\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bC6gEC58Z9z"
      },
      "outputs": [],
      "source": [
        "# Reset the augmented data generator\n",
        "\n",
        "train_generator_aug = get_generator(image_gen_aug, train_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNATPHjd8Z90"
      },
      "source": [
        "#### Train a new model on the augmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaUaK5qr8Z91"
      },
      "outputs": [],
      "source": [
        "# Build and compile a new model\n",
        "\n",
        "lsun_new_model = get_model((64, 64, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "nadx8n758Z92"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "\n",
        "history_augmented = train_model(lsun_new_model, train_generator_aug, valid_generator_aug, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do4bZI1R8Z92"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "gCSouJTj8Z93"
      },
      "outputs": [],
      "source": [
        "# plot accuracy vs epoch and loss vs epoch\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(121)\n",
        "try:\n",
        "    plt.plot(history_augmented.history['accuracy'])\n",
        "    plt.plot(history_augmented.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    try:\n",
        "        plt.plot(history_augmented.history['acc'])\n",
        "        plt.plot(history_augmented.history['val_acc'])\n",
        "    except KeyError:\n",
        "        plt.plot(history_augmented.history['categorical_accuracy'])\n",
        "        plt.plot(history_augmented.history['val_categorical_accuracy'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(history_augmented.history['loss'])\n",
        "plt.plot(history_augmented.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZukFxoD8Z93"
      },
      "source": [
        "#### Get predictions using the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZjKrQi-8Z94"
      },
      "outputs": [],
      "source": [
        "# Get model predictions for the first 3 batches of test data\n",
        "\n",
        "num_batches = 3\n",
        "seed = 25\n",
        "test_generator = get_generator(image_gen_aug, test_dir, seed=seed)\n",
        "predictions = lsun_new_model.predict_generator(test_generator, steps=num_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgbyB71N8Z94"
      },
      "outputs": [],
      "source": [
        "# view randomly selected images and model predictions\n",
        "\n",
        "# Get images and ground truth labels\n",
        "test_generator = get_generator(image_gen_aug, test_dir, seed=seed)\n",
        "batches = []\n",
        "for i in range(num_batches):\n",
        "    batches.append(next(test_generator))\n",
        "    \n",
        "batch_images = np.vstack([b[0] for b in batches])\n",
        "batch_labels = np.concatenate([b[1].astype(np.int32) for b in batches])\n",
        "\n",
        "# Randomly select images from the batch\n",
        "inx = np.random.choice(predictions.shape[0], 4, replace=False)\n",
        "print(inx)\n",
        "\n",
        "fig, axes = plt.subplots(4, 2, figsize=(16, 12))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=-0.2)\n",
        "\n",
        "for n, i in enumerate(inx):\n",
        "    axes[n, 0].imshow(batch_images[i])\n",
        "    axes[n, 0].get_xaxis().set_visible(False)\n",
        "    axes[n, 0].get_yaxis().set_visible(False)\n",
        "    axes[n, 0].text(30., -3.5, lsun_classes[np.where(batch_labels[i] == 1.)[0][0]], \n",
        "                    horizontalalignment='center')\n",
        "    axes[n, 1].bar(np.arange(len(predictions[i])), predictions[i])\n",
        "    axes[n, 1].set_xticks(np.arange(len(predictions[i])))\n",
        "    axes[n, 1].set_xticklabels(lsun_classes)\n",
        "    axes[n, 1].set_title(f\"Categorical distribution. Model prediction: {lsun_classes[np.argmax(predictions[i])]}\")\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvf9cs3L8Z95"
      },
      "source": [
        "### Part 2: tf.data\n",
        "\n",
        "![CIFAR-100 overview image](data/cifar100/cifar100.png)\n",
        "\n",
        "#### The CIFAR-100 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86i-bUHW8Z95"
      },
      "source": [
        "In the second part of this assignment, you will use the [CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). This image dataset has 100 classes with 500 training images and 100 test images per class. \n",
        "\n",
        "* A. Krizhevsky. \"Learning Multiple Layers of Features from Tiny Images\". April 2009 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh3g5Etv8Z96"
      },
      "source": [
        "#### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY51awYv8Z96"
      },
      "outputs": [],
      "source": [
        "# Load the data, along with the labels\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = cifar100.load_data(label_mode='fine')\n",
        "with open('data/cifar100/cifar100_labels.json', 'r') as j:\n",
        "    cifar_labels = json.load(j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUZgc22Z8Z97"
      },
      "source": [
        "#### Display sample images and labels from the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "vK6WEFVa8Z97"
      },
      "outputs": [],
      "source": [
        "# Display a few images and labels\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "inx = np.random.choice(train_data.shape[0], 32, replace=False)\n",
        "for n, i in enumerate(inx):\n",
        "    ax = plt.subplot(4, 8, n+1)\n",
        "    plt.imshow(train_data[i])\n",
        "    plt.title(cifar_labels[int(train_labels[i])])\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NFRAIWC8Z98"
      },
      "source": [
        "#### Create Dataset objects for the train and test images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idXI4Y0k8Z99"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def create_dataset(data, labels):\n",
        "    \n",
        "    dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "    dataset.batch(16, drop_remainder=True)\n",
        "    return dataset    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MAJz0le8Z99"
      },
      "outputs": [],
      "source": [
        "# convert the training and test data and labels into datasets\n",
        "\n",
        "train_dataset = create_dataset(train_data, train_labels)\n",
        "test_dataset = create_dataset(test_data, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVPv42jw8Z99"
      },
      "outputs": [],
      "source": [
        "# Check the element_spec of your datasets\n",
        "\n",
        "print(train_dataset.element_spec)\n",
        "print(test_dataset.element_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuWgn7BG8Z9-"
      },
      "source": [
        "#### Filter the Dataset\n",
        "\n",
        "[`tf.equal`](https://www.tensorflow.org/api_docs/python/tf/math/equal), [`tf.cast`](https://www.tensorflow.org/api_docs/python/tf/dtypes/cast) and [`tf.math.reduce_any`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_any) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsVA7uWD8Z9-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def filter_classes(dataset, classes):\n",
        "   \n",
        "    def filter_auxiliary(image, label):\n",
        "        return tf.math.reduce_any(tf.equal(label, classes))\n",
        "    \n",
        "    return dataset.filter(filter_auxiliary)    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dj61vkao8Z9_"
      },
      "outputs": [],
      "source": [
        "# filter the datasets using your function\n",
        "\n",
        "cifar_classes = [0, 29, 99] # datasets should contain only classes in this list\n",
        "\n",
        "train_dataset = filter_classes(train_dataset, cifar_classes)\n",
        "test_dataset = filter_classes(test_dataset, cifar_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db5YU8rB8Z-A"
      },
      "source": [
        "#### Apply map functions to the Dataset\n",
        "\n",
        "\n",
        "\n",
        "* Class 0 maps to `[1., 0., 0.]`\n",
        "* Class 29 maps to `[0., 1., 0.]`\n",
        "* Class 99 maps to `[0., 0., 1.]`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf5_XrR-8Z-A"
      },
      "outputs": [],
      "source": [
        "\n",
        "def map_labels(dataset):\n",
        "    \n",
        "    def map_auxiliary(image,label):\n",
        "        if label == 0:\n",
        "            return (image, tf.constant([1., 0., 0.]))\n",
        "        elif label == 29:\n",
        "            return (image, tf.constant([0., 1., 0.]))\n",
        "        else:\n",
        "            return (image, tf.constant([0., 0., 1.]))\n",
        "        \n",
        "    return dataset.map(map_auxiliary)    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR-mV_EU8Z-B"
      },
      "outputs": [],
      "source": [
        "# one-hot encode the training and test labels.\n",
        "\n",
        "train_dataset = map_labels(train_dataset)\n",
        "test_dataset = map_labels(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YSetzHV8Z-B"
      },
      "source": [
        "The second function should process the images according to the following specification:\n",
        " [`tf.reduce_mean`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean?version=stable) since the black and white image is the colour-average of the colour images. You can also use the `keepdims` keyword in `tf.reduce_mean` to retain the single colour channel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LBB1Bn98Z-C"
      },
      "outputs": [],
      "source": [
        "\n",
        "def map_images(dataset):\n",
        "    \n",
        "    def map_auxiliary(image, label):\n",
        "        image = image/255\n",
        "        image = tf.reduce_mean(image, axis = 2, keepdims= True)\n",
        "        return image, label\n",
        "    \n",
        "    return dataset.map(map_auxiliary)    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-r1kEps8Z-C"
      },
      "outputs": [],
      "source": [
        "# apply your mapping function to the datasets\n",
        "\n",
        "train_dataset_bw = map_images(train_dataset)\n",
        "test_dataset_bw = map_images(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdfEUk0G8Z-D"
      },
      "source": [
        "#### Display a batch of processed images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-8Z8jGt8Z-D"
      },
      "outputs": [],
      "source": [
        "# view a selection of images before and after processing\n",
        "\n",
        "plt.figure(figsize=(16,5))\n",
        "plt.suptitle(\"Unprocessed images\", fontsize=16)\n",
        "for n, elem in enumerate(train_dataset.take(10)):\n",
        "    images, labels = elem\n",
        "    ax = plt.subplot(2, 5, n+1)\n",
        "    plt.title(cifar_labels[cifar_classes[np.where(labels == 1.)[0][0]]])\n",
        "    plt.imshow(np.squeeze(images), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    \n",
        "plt.figure(figsize=(16,5))\n",
        "plt.suptitle(\"Processed images\", fontsize=16)\n",
        "for n, elem in enumerate(train_dataset_bw.take(10)):\n",
        "    images_bw, labels_bw = elem\n",
        "    ax = plt.subplot(2, 5, n+1)\n",
        "    plt.title(cifar_labels[cifar_classes[np.where(labels_bw == 1.)[0][0]]])\n",
        "    plt.imshow(np.squeeze(images_bw), cmap='gray')\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su85eumd8Z-E"
      },
      "outputs": [],
      "source": [
        "# batch the training dataset and expand the final dimensinos\n",
        "\n",
        "train_dataset_bw = train_dataset_bw.batch(10)\n",
        "train_dataset_bw = train_dataset_bw.shuffle(100)\n",
        "\n",
        "test_dataset_bw = test_dataset_bw.batch(10)\n",
        "test_dataset_bw = test_dataset_bw.shuffle(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2VBvKZq8Z-F"
      },
      "source": [
        "#### Train a neural network model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYFHwPGM8Z-F"
      },
      "outputs": [],
      "source": [
        "# Build and compile a new model with our original spec, using the new image size\n",
        "    \n",
        "cifar_model = get_model((32, 32, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "oZkB2q1_8Z-G"
      },
      "outputs": [],
      "source": [
        "# Train the model for 15 epochs\n",
        "\n",
        "history = cifar_model.fit(train_dataset_bw, validation_data=test_dataset_bw, epochs=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74KpEECS8Z-G"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_1QihbE8Z-G"
      },
      "outputs": [],
      "source": [
        "# plot accuracy vs epoch and loss vs epoch\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(121)\n",
        "try:\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    try:\n",
        "        plt.plot(history.history['acc'])\n",
        "        plt.plot(history.history['val_acc'])\n",
        "    except KeyError:\n",
        "        plt.plot(history.history['categorical_accuracy'])\n",
        "        plt.plot(history.history['val_categorical_accuracy'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsBAuj4q8Z-H"
      },
      "outputs": [],
      "source": [
        "# Create an iterable from the batched test dataset\n",
        "\n",
        "test_dataset = test_dataset.batch(10)\n",
        "iter_test_dataset = iter(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2vuqLsK8Z-I"
      },
      "outputs": [],
      "source": [
        "# Display model predictions for a sample of test images\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "inx = np.random.choice(test_data.shape[0], 18, replace=False)\n",
        "images, labels = next(iter_test_dataset)\n",
        "probs = cifar_model(tf.reduce_mean(tf.cast(images, tf.float32), axis=-1, keepdims=True) / 255.)\n",
        "preds = np.argmax(probs, axis=1)\n",
        "for n in range(10):\n",
        "    ax = plt.subplot(2, 5, n+1)\n",
        "    plt.imshow(images[n])\n",
        "    plt.title(cifar_labels[cifar_classes[np.where(labels[n].numpy() == 1.0)[0][0]]])\n",
        "    plt.text(0, 35, \"Model prediction: {}\".format(cifar_labels[cifar_classes[preds[n]]]))\n",
        "    plt.axis('off')"
      ]
    }
  ],
  "metadata": {
    "coursera": {
      "course_slug": "tensor-flow-2-2",
      "graded_item_id": "3hWzU",
      "launcher_item_id": "AStQh"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}