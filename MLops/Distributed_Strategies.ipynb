{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "# Distributed Strategies with TF and Keras\n",
    "------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yL0-KcLPwtk"
   },
   "source": [
    "We are going to perform a distributed training strategy using TensorFlow and Keras, specifically the [`tf.distribute.MultiWorkerMirroredStrategy`](https://www.tensorflow.org/api_docs/python/tf/distribute/MultiWorkerMirroredStrategy). \n",
    "\n",
    "With the help of this strategy, a Keras model that was designed to run on single-worker can seamlessly work on multiple workers with minimal code change. In particular we will:\n",
    "\n",
    "\n",
    "1. Perform training with a single worker.\n",
    "2. Understand the requirements for a multi-worker setup (`tf_config` variable) and using context managers for implementing distributed strategies.\n",
    "3. Use magic commands to simulate different machines.\n",
    "4. Perform a multi-worker training strategy.\n",
    "\n",
    "Take a look of  the official [Multi-worker training with Keras](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras) notebook, which covers some additional topics.\n",
    "\n",
    "[Distributed Training with TensorFlow](https://www.tensorflow.org/guide/distributed_training) guide is also available for an overview of the distribution strategies TensorFlow supports for those interested in a deeper understanding of `tf.distribute.Strategy` APIs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUXex9ctTuDB"
   },
   "source": [
    "## Setup\n",
    "\n",
    "First, some necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bnYxvfLD-LW-",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Log additional outputs from TF's C++ backend\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zz0EY91y3mxy"
   },
   "source": [
    "Before importing TensorFlow, make a few changes to the environment.\n",
    "\n",
    "- Disable all GPUs. This prevents errors caused by the workers all trying to use the same GPU. **For a real application each worker would be on a different machine.**\n",
    "\n",
    "\n",
    "- Add the current directory to python's path so modules in this directory can be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "685pbYEY3jGC",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Disable GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# Add current directory to path\n",
    "if '.' not in sys.path:\n",
    "  sys.path.insert(0, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd4L9Ii77SS8"
   },
   "source": [
    "The previous step is important since this notebook relies on writting files using the magic command `%%writefile` and then importing them as modules.\n",
    "\n",
    "Now that the environment configuration is ready, import TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vHNvttzV43sA",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Ignore warnings\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0S2jpf6Sx50i"
   },
   "source": [
    "### Dataset and model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLW6D2TzvC-4"
   },
   "source": [
    "Next create an `mnist.py` file with a simple model and dataset setup. This python file will be used by the worker-processes.\n",
    "\n",
    "The name of this file derives from the dataset we will be using which is called [mnist](https://keras.io/api/datasets/mnist/) and consists of 60,000 28x28 grayscale images of the first 10 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dma_wUAxZqo2",
    "outputId": "4d80db38-8f95-4480-d1d5-0c943db1d6d3",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist.py\n",
    "\n",
    "# import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def mnist_dataset(batch_size):\n",
    "  # Load the data\n",
    "  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "  # Normalize pixel values for x_train and cast to float32\n",
    "  x_train = x_train / np.float32(255)\n",
    "  # Cast y_train to int64\n",
    "  y_train = y_train.astype(np.int64)\n",
    "  # Define repeated and shuffled dataset\n",
    "  train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).repeat().batch(batch_size)\n",
    "  return train_dataset\n",
    "\n",
    "\n",
    "def build_and_compile_cnn_model():\n",
    "  # Define simple CNN model using Keras Sequential\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  # Compile model\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "      metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbDEKpGowcyT"
   },
   "source": [
    "Check that the file was succesfully created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxsnfpVurQ1g",
    "outputId": "1315df00-df3c-416c-b105-e12b374de7ff",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist.py\n"
     ]
    }
   ],
   "source": [
    "!ls *.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UL3kisMO90X"
   },
   "source": [
    "Import the mnist module we just created and try training the model for a small number of epochs to observe the results of a single worker to make sure everything works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Qe6iAf5O8iJ",
    "outputId": "f8c922b4-89a1-4b5f-b369-25964e5daceb",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n",
      "Epoch 1/3\n",
      "70/70 [==============================] - 5s 48ms/step - loss: 2.2800 - accuracy: 0.1560\n",
      "Epoch 2/3\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 2.2170 - accuracy: 0.3607\n",
      "Epoch 3/3\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 2.1480 - accuracy: 0.5201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3173711df0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import your mnist model\n",
    "import mnist\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Load the dataset\n",
    "single_worker_dataset = mnist.mnist_dataset(batch_size)\n",
    "\n",
    "# Load compiled CNN model\n",
    "single_worker_model = mnist.build_and_compile_cnn_model()\n",
    "\n",
    "# As training progresses, the loss should drop and the accuracy should increase.\n",
    "single_worker_model.fit(single_worker_dataset, epochs=3, steps_per_epoch=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpLPWFJh1CAK"
   },
   "source": [
    "Everything is working as expected! \n",
    "\n",
    "Now we will see how multiple workers can be used as a distributed strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmgZwwymxqt5"
   },
   "source": [
    "## Multi-worker Configuration\n",
    "\n",
    "Now let's enter the world of multi-worker training. In TensorFlow, the `TF_CONFIG` environment variable is required for training on multiple machines, each of which possibly has a different role. `TF_CONFIG` is a JSON string used to specify the cluster configuration on each worker that is part of the cluster.\n",
    "\n",
    "There are two components of `TF_CONFIG`: `cluster` and `task`. \n",
    "\n",
    "Let's dive into how they are used:\n",
    "\n",
    "`cluster`:\n",
    "- **It is the same for all workers** and provides information about the training cluster, which is a dict consisting of different types of jobs such as `worker`.\n",
    "\n",
    "- In multi-worker training with `MultiWorkerMirroredStrategy`, there is usually one `worker` that takes on a little more responsibility like saving checkpoint and writing summary file for TensorBoard in addition to what a regular `worker` does. \n",
    "-Such a worker is referred to as the `chief` worker, and it is customary that the `worker` with `index` 0 is appointed as the chief `worker` (in fact this is how `tf.distribute.Strategy` is implemented).\n",
    "\n",
    "`task`:\n",
    "- Provides information of the current task and is different on each worker. It specifies the `type` and `index` of that worker. \n",
    "\n",
    "Here is an example configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XK1eTYvSZiX7",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "tf_config = {\n",
    "    'cluster': {\n",
    "        'worker': ['localhost:12345', 'localhost:23456']\n",
    "    },\n",
    "    'task': {'type': 'worker', 'index': 0}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjgwJbPKZkJL"
   },
   "source": [
    "Here is the same `TF_CONFIG` serialized as a JSON string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yY-T0YDQZjbu",
    "outputId": "a46a0e43-22d3-4d36-fe05-1995c1212b10",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'{\"cluster\": {\"worker\": [\"localhost:12345\", \"localhost:23456\"]}, \"task\": {\"type\": \"worker\", \"index\": 0}}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(tf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YFpxrcsZ2xG"
   },
   "source": [
    "### Explaining the TF_CONFIG example\n",
    "\n",
    "In this example we set a `TF_CONFIG` with 2 workers on `localhost`. In practice, users would create multiple workers on external IP addresses/ports, and set `TF_CONFIG` on each worker appropriately.\n",
    "\n",
    "Since we set the task `type` to `\"worker\"` and the task `index` to `0`, **this machine is the first worker and will be appointed as the chief worker**. \n",
    "\n",
    "Note that other machines will need to have the `TF_CONFIG` environment variable set as well, and it should have the same `cluster` dict, but different task `type` or task `index` depending on what the roles of those machines are. For instance, for the second worker you would set `tf_config['task']['index']=1`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f83FVYqDX3aX"
   },
   "source": [
    "### Quick Note on Environment variables and subprocesses in notebooks\n",
    "\n",
    "Above, `tf_config` is just a local variable in python. To actually use it to configure training, this dictionary needs to be serialized as JSON, and placed in the `TF_CONFIG` environment variable.\n",
    "\n",
    "In the next section, we'll spawn new subprocesses for each worker using the `%%bash` magic command. Subprocesses inherit environment variables from their parent, so they can access `TF_CONFIG`. \n",
    "\n",
    "We would never really launch our jobs this way (as subprocesses of an interactive Python runtime), but it's how you will do it for learning propouses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhNtHfuxCGVy"
   },
   "source": [
    "## Choose the right strategy\n",
    "\n",
    "In TensorFlow there are two main forms of distributed training:\n",
    "\n",
    "* Synchronous training, where the steps of training are synced across the workers and replicas, and\n",
    "* Asynchronous training, where the training steps are not strictly synced.\n",
    "\n",
    "`MultiWorkerMirroredStrategy`, which is the recommended strategy for synchronous multi-worker training is the one you will be using.\n",
    "\n",
    "To train the model, use an instance of `tf.distribute.MultiWorkerMirroredStrategy`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1uFSHCJXMrQ-",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0iv7SyyAohc"
   },
   "source": [
    "`MultiWorkerMirroredStrategy` creates copies of all variables in the model's layers on each device across all workers.  It uses `CollectiveOps`, a TensorFlow op for collective communication, to aggregate gradients and keep the variables in sync.  The [official TF distributed training guide](https://www.tensorflow.org/guide/distributed_training) has more details about this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H47DDcOgfzm7"
   },
   "source": [
    "### Implement Distributed Training via Context Managers\n",
    "\n",
    "To distribute the training to multiple-workers all you need to do is to enclose the model building and `model.compile()` call inside `strategy.scope()`. \n",
    "\n",
    "The distribution strategy's scope dictates how and where the variables are created, and in the case of `MultiWorkerMirroredStrategy`, the variables created are `MirroredVariable`s, and they are replicated on each of the workers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wo6b9wX65glL",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Implementing distributed strategy via a context manager\n",
    "with strategy.scope():\n",
    "  multi_worker_model = mnist.build_and_compile_cnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfYpmIxO6Jck"
   },
   "source": [
    "Note: `TF_CONFIG` is parsed and TensorFlow's GRPC servers are started at the time `MultiWorkerMirroredStrategy()` is called, so the `TF_CONFIG` environment variable must be set before a `tf.distribute.Strategy` instance is created. \n",
    "\n",
    "**Since `TF_CONFIG` is not set yet the above strategy is effectively single-worker training**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxzYhF0dL6qQ"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "### Create training script\n",
    "\n",
    "To actually run with `MultiWorkerMirroredStrategy` we'll need to run worker processes and pass a `TF_CONFIG` to them.\n",
    "\n",
    "Like the `mnist.py` file written earlier, here is the `main.py` that each of the workers will run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BcsuBYrpgnlS",
    "outputId": "26fa7d73-a239-4d62-efb8-29ea7a273608",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import mnist # Your module\n",
    "\n",
    "# Define batch size\n",
    "per_worker_batch_size = 64\n",
    "\n",
    "# Get TF_CONFIG from the env variables and save it as JSON\n",
    "tf_config = json.loads(os.environ['TF_CONFIG'])\n",
    "\n",
    "# Infer number of workers from tf_config\n",
    "num_workers = len(tf_config['cluster']['worker'])\n",
    "\n",
    "# Define strategy\n",
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "# Define global batch size\n",
    "global_batch_size = per_worker_batch_size * num_workers\n",
    "\n",
    "# Load dataset\n",
    "multi_worker_dataset = mnist.mnist_dataset(global_batch_size)\n",
    "\n",
    "# Create and compile model following the distributed strategy\n",
    "with strategy.scope():\n",
    "  multi_worker_model = mnist.build_and_compile_cnn_model()\n",
    "\n",
    "# Train the model\n",
    "multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aom9xelvJQ_6"
   },
   "source": [
    "In the code snippet above note that the `global_batch_size`, which gets passed to `Dataset.batch`, is set to `per_worker_batch_size * num_workers`. This ensures that each worker processes batches of `per_worker_batch_size` examples regardless of the number of workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHLhOii67Saa"
   },
   "source": [
    "The current directory should now contain both Python files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bi6x05Sr60O9",
    "outputId": "611d962e-6fbc-4854-aed3-fe153aec5b30",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main.py  mnist.py\n"
     ]
    }
   ],
   "source": [
    "!ls *.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmEEStPS6vR_"
   },
   "source": [
    "### Set TF_CONFIG environment variable\n",
    "\n",
    "Now json-serialize the `TF_CONFIG` and add it to the environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9uu3g7vV7Bbt",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Set TF_CONFIG env variable\n",
    "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WDqwMPNneON"
   },
   "source": [
    "And terminate all background processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "txMXaq8d8N_S",
    "outputId": "ebc2ba09-b0db-4ee2-b325-1d41b63a4484",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All background processes were killed.\n"
     ]
    }
   ],
   "source": [
    "# first kill any previous runs\n",
    "%killbgscripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_KAevP0akTK"
   },
   "source": [
    "Before launching the first worker we can check that port `12345` is free at the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "amapr6GKakTK",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# This should not print anything at the moment\n",
    "!lsof -i :12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsY3dQLK7jdf"
   },
   "source": [
    "### Launch the first worker\n",
    "\n",
    "Now, we can launch a worker process that will run the `main.py` and use the `TF_CONFIG`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qnSma_Ck7r-r",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "python main.py &> job_0.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZChyazqS7v0P"
   },
   "source": [
    "There are a few things to note about the above command:\n",
    "\n",
    "1. It uses the `%%bash` which is a [notebook \"magic\"](https://ipython.readthedocs.io/en/stable/interactive/magics.html) to run some bash commands.\n",
    "2. It uses the `--bg` flag to run the `bash` process in the background, because this worker will not terminate. It waits for all the workers before it starts.\n",
    "\n",
    "The backgrounded worker process won't print output to this notebook, so the `&>` redirects its output to a file, so you can see what happened.\n",
    "\n",
    "So, wait a few seconds for the process to start up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Hm2yrULE9281",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Wait for logs to be written to the file\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swWu8yyqakTP"
   },
   "source": [
    "Now we can check again at the status of port `12345`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FNL0fYNkakTQ",
    "outputId": "f5c8111c-e345-47c8-83b3-e6a349c2ca0f",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
      "python3 1920 root    5u  IPv4  56219      0t0  TCP *:12345 (LISTEN)\n",
      "python3 1920 root   12u  IPv4  56246      0t0  TCP localhost:44920->localhost:12345 (ESTABLISHED)\n",
      "python3 1920 root   13u  IPv4  56247      0t0  TCP localhost:12345->localhost:44920 (ESTABLISHED)\n"
     ]
    }
   ],
   "source": [
    "!lsof -i :12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFPoNxg_9_Mx"
   },
   "source": [
    "Now look what's been output to the worker's logfile so far using the `cat` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZEOuVgQ9-hn",
    "outputId": "f1cc2a32-1872-485a-87ed-a811fd1c817f",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-18 03:37:42.525499: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 03:37:43.842098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-04-18 03:37:45.669318: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:450] Started server with target: grpc://localhost:12345\n",
      "2023-04-18 03:37:45.677345: I tensorflow/tsl/distributed_runtime/coordination/coordination_service.cc:525] /job:worker/replica:0/task:0 has connected to coordination service. Incarnation: 923616123868988248\n",
      "2023-04-18 03:37:45.684907: I tensorflow/tsl/distributed_runtime/coordination/coordination_service_agent.cc:298] Coordination agent has successfully connected.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat job_0.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqZhVF7L_KOy"
   },
   "source": [
    "The last line of the log file should say: `Started server with target: grpc://localhost:12345`. The first worker is now ready, and is waiting for all the other worker(s) to be ready to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pi8vPNNA_l4a"
   },
   "source": [
    "### Launch the second worker\n",
    "\n",
    "Now update the `tf_config` for the second worker's process to pick up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "lAiYkkPu_Jqd",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "tf_config['task']['index'] = 1\n",
    "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AshGVO0_x0w"
   },
   "source": [
    "Now launch the second worker. This will start the training since all the workers are active (so there's no need to background this process):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ESVtyQ9_xjx",
    "outputId": "2a8a2423-5db7-4156-b360-600984cc09d8",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "70/70 [==============================] - 19s 223ms/step - loss: 2.2614 - accuracy: 0.2542\n",
      "Epoch 2/3\n",
      "70/70 [==============================] - 14s 193ms/step - loss: 2.1884 - accuracy: 0.4336\n",
      "Epoch 3/3\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 2.1070 - accuracy: 0.5558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 03:38:54.933084: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 03:38:56.308973: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-04-18 03:38:58.987731: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:450] Started server with target: grpc://localhost:23456\n",
      "2023-04-18 03:38:58.997398: I tensorflow/tsl/distributed_runtime/coordination/coordination_service_agent.cc:298] Coordination agent has successfully connected.\n",
      "2023-04-18 03:39:01.249187: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [60000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-18 03:39:01.249945: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [60000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-18 03:39:01.252219: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 60000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 28\n",
      "        }\n",
      "        dim {\n",
      "          size: 28\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-04-18 03:39:01.643666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [60000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-18 03:39:01.649354: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [60000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-18 03:39:01.863197: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-04-18 03:39:01.863897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX4FA2O2AuAn"
   },
   "source": [
    "Now if we recheck the logs written by the first worker you'll see that it participated in training that model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rc6hw3yTBKXX",
    "outputId": "3143d50f-5e30-4c63-8c14-995965283ced",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-18 03:37:42.525499: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 03:37:43.842098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-04-18 03:37:45.669318: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:450] Started server with target: grpc://localhost:12345\n",
      "2023-04-18 03:37:45.677345: I tensorflow/tsl/distributed_runtime/coordination/coordination_service.cc:525] /job:worker/replica:0/task:0 has connected to coordination service. Incarnation: 923616123868988248\n",
      "2023-04-18 03:37:45.684907: I tensorflow/tsl/distributed_runtime/coordination/coordination_service_agent.cc:298] Coordination agent has successfully connected.\n",
      "2023-04-18 03:38:58.997009: I tensorflow/tsl/distributed_runtime/coordination/coordination_service.cc:525] /job:worker/replica:0/task:1 has connected to coordination service. Incarnation: 6451028238582618508\n",
      "2023-04-18 03:39:01.240551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [60000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-18 03:39:01.241194: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [60000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-18 03:39:01.243430: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 60000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 28\n",
      "        }\n",
      "        dim {\n",
      "          size: 28\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-04-18 03:39:01.638260: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [60000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-18 03:39:01.638990: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [60000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-18 03:39:01.856705: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-04-18 03:39:01.857459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Epoch 1/3\n",
      "70/70 [==============================] - 19s 222ms/step - loss: 2.2614 - accuracy: 0.2542\n",
      "Epoch 2/3\n",
      "70/70 [==============================] - 14s 193ms/step - loss: 2.1884 - accuracy: 0.4336\n",
      "Epoch 3/3\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 2.1070 - accuracy: 0.5558\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat job_0.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zL79ak5PMzEg"
   },
   "source": [
    "Unsurprisingly this ran _slower_ than the the test run at the beginning . **Running multiple workers on a single machine only adds overhead**. The goal here was not to improve the training time, but only to give an example of multi-worker training."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "C3W3_Colab_Lab1_Distributed_Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
