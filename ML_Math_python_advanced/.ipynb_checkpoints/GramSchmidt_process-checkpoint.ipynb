{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqM5mBuRc1Fk"
      },
      "source": [
        "# Gram-Schmidt process\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "m6StfsZgc1Fw"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "\n",
        "verySmallNumber = 1e-14 # That's 1×10⁻¹⁴ = 0.00000000000001\n",
        "\n",
        "\n",
        "def gsBasis4(A) :\n",
        "    B = np.array(A, dtype=np.float_) # Make B as a copy of A, since we're going to alter it's values.\n",
        "    # The zeroth column is easy, since it has no other vectors to make it normal to.\n",
        "    # All that needs to be done is to normalise it. I.e. divide by its modulus, or norm.\n",
        "    B[:, 0] = B[:, 0] / la.norm(B[:, 0])\n",
        "    # For the first column, we need to subtract any overlap with our new zeroth vector.\n",
        "    B[:, 1] = B[:, 1] - B[:, 1] @ B[:, 0] * B[:, 0]\n",
        "    # If there's anything left after that subtraction, then B[:, 1] is linearly independant of B[:, 0]\n",
        "    # If this is the case, we can normalise it. Otherwise we'll set that vector to zero.\n",
        "    if la.norm(B[:, 1]) > verySmallNumber :\n",
        "        B[:, 1] = B[:, 1] / la.norm(B[:, 1])\n",
        "    else :\n",
        "        B[:, 1] = np.zeros_like(B[:, 1])\n",
        "    # Now we need to repeat the process for column 2.\n",
        "    # Insert two lines of code, the first to subtract the overlap with the zeroth vector,\n",
        "    # and the second to subtract the overlap with the first.\n",
        "    B[:, 2] = B[:, 2] - B[:, 2] @ B[:, 0] * B[:, 0] - B[:, 2] @ B[:, 1] * B[:, 1]\n",
        "    \n",
        "    # Again we'll need to normalise our new vector.\n",
        "    # Copy and adapt the normalisation fragment from above to column 2.\n",
        "    if la.norm(B[:, 2]) > verySmallNumber :\n",
        "        B[:, 2] = B[:, 2] / la.norm(B[:, 2])\n",
        "    else :\n",
        "        B[:, 2] = np.zeros_like(B[:, 2])\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Finally, column three:\n",
        "    # Insert code to subtract the overlap with the first three vectors.\n",
        "    \n",
        "    B[:, 3] = B[:, 3] - B[:, 3] @ B[:, 0] * B[:, 0] - B[:, 3] @ B[:, 1] * B[:, 1]- B[:, 3] @ B[:, 2] * B[:, 2]\n",
        "    \n",
        "    # Now normalise if possible\n",
        "    if la.norm(B[:, 3]) > verySmallNumber :\n",
        "        B[:, 3] = B[:, 3] / la.norm(B[:, 3])\n",
        "    else :\n",
        "        B[:, 3] = np.zeros_like(B[:, 3])\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Finally, we return the result:\n",
        "    return B\n",
        "\n",
        "\n",
        "\n",
        "def gsBasis(A) :\n",
        "    B = np.array(A, dtype=np.float_) # Make B as a copy of A, since we're going to alter it's values.\n",
        "    # Loop over all vectors, starting with zero, label them with i\n",
        "    for i in range(B.shape[1]) :\n",
        "        # Inside that loop, loop over all previous vectors, j, to subtract.\n",
        "        for j in range(i) :\n",
        "            # Complete the code to subtract the overlap with previous vectors.\n",
        "            # you'll need the current vector B[:, i] and a previous vector B[:, j]\n",
        "            B[:, i] = B[:,i]-B[:,i]@ B[:, j] * B[:, j]\n",
        "            j+=1\n",
        "        # Next insert code to do the normalisation test for B[:, i]\n",
        "        if la.norm(B[:, i]) > verySmallNumber :\n",
        "            B[:, i] = B[:, i] / la.norm(B[:, i])\n",
        "        else :\n",
        "            B[:, i] = np.zeros_like(B[:, i])\n",
        "        \n",
        "        i+=1\n",
        "          \n",
        "    # Finally, we return the result:\n",
        "    return B\n",
        "\n",
        "# Uses the Gram-schmidt process to calculate the dimension\n",
        "# spanned by a list of vectors.\n",
        "# Since each vector is normalised to one, or is zero,\n",
        "# the sum of all the norms will be the dimension.\n",
        "def dimensions(A) :\n",
        "    return np.sum(la.norm(gsBasis(A), axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4G0gY3idc1F9"
      },
      "outputs": [],
      "source": [
        "V = np.array([[1,0,2,6],\n",
        "              [0,1,8,2],\n",
        "              [2,8,3,1],\n",
        "              [1,-6,2,3]], dtype=np.float_)\n",
        "gsBasis4(V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "F4-gjJYJc1GB"
      },
      "outputs": [],
      "source": [
        "\n",
        "U = gsBasis4(V)\n",
        "gsBasis4(U)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "H4qHCvTbc1GC"
      },
      "outputs": [],
      "source": [
        "\n",
        "gsBasis(V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1eCqggrac1GE"
      },
      "outputs": [],
      "source": [
        "\n",
        "A = np.array([[3,2,3],\n",
        "              [2,5,-1],\n",
        "              [2,4,8],\n",
        "              [12,2,1]], dtype=np.float_)\n",
        "gsBasis(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "D17o5zZyc1GG"
      },
      "outputs": [],
      "source": [
        "dimensions(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "L5z_flVec1GI"
      },
      "outputs": [],
      "source": [
        "B = np.array([[6,2,1,7,5],\n",
        "              [2,8,5,-4,1],\n",
        "              [1,-6,3,2,8]], dtype=np.float_)\n",
        "gsBasis(B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "m5ZIF8W5c1GK"
      },
      "outputs": [],
      "source": [
        "dimensions(B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PV_D93f8c1GM"
      },
      "outputs": [],
      "source": [
        "\n",
        "C = np.array([[1,0,2],\n",
        "              [0,1,-3],\n",
        "              [1,0,2]], dtype=np.float_)\n",
        "gsBasis(C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NNUM9IAxc1GO"
      },
      "outputs": [],
      "source": [
        "dimensions(C)"
      ]
    }
  ],
  "metadata": {
    "coursera": {
      "course_slug": "linear-algebra-machine-learning",
      "graded_item_id": "FNk8v",
      "launcher_item_id": "DdvVk"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}